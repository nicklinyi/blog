---
title: ComfyUI生成粘土风格照片
date: 2024-05-09
author: Nick
categories: [AI]
tags: [GPU, Cuda, Ubuntu, clay]
slug: comfyui
---

本文介绍如何在 Ubuntu 22.04 LTS 上安装comfyUI，并生成粘土风格照片 。

## 安装comfyUI
由于在linux系统下只能手动安装，因此，可参考官网(https://github.com/comfyanonymous/ComfyUI)的Manual Install部分的内容进行安装

1.下载程序包
```
$ git clone https://github.com/comfyanonymous/ComfyUI.git
```

2.由于本人的电脑含Nvidia的GPU显卡，所以这里安装的是NVIDIA版本的pytorch，具体命令如下
```
$ conda create -n comfyui
$ conda activate comfyui
$ conda install pip
$ pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121
```

如果没有报错就表明安装完成了。

## 安装comfyui-manager
comfyui-manager(https://github.com/ltdrdata/ComfyUI-Manager)用于管理和安装第三方开发的一些附加功能,安装非常简单，就是把软件包下载下来，然后
拷贝到`ComfyUI/custom_nodes/`即可
```
$ cd ComfyUI/custom_nodes
$ git clone https://github.com/ltdrdata/ComfyUI-Manager.git
```

## 下载IMAGE TO CLAY STYLE (Ollama)流程
从https://openart.ai/workflows/datou/image-to-clay-style-ollama/Rhj7m1hsDRfDm65jOmxD 网站下载即可，网页上有一个'Download'的链接，点击下载即可。

## 运行comfyUI
```
# 回到ComfyUI的根目录下运行
$ python main.py
```
打开浏览器，输入：http://127.0.0.1:8188 即可打开ComfyUI的界面，然后把刚才下载的流程的json文件拖到浏览器中，即可打开该工作流程。一般会提示报错，此时可以
点击界面右下角的`Manager`，打开comfyui-manager，然后点击`Install Missing Custom Nodes`，安装所有缺的插件即可。

## 下载模型：
Checkpoints模型：CinematicRedmond.safetensors，链接：https://huggingface.co/artificialguybr/CinematicRedmond-SDXL/tree/main
Checkpoints模型下载完后放在`ComfyUI/models/checkpoints/`目录下。

两个LoRAs模型：
CLAYMATE_V2.03_.safetensors，链接：https://huggingface.co/nerualdreming/Best_LoRas_Mar24/blob/main/CLAYMATE_V2.03_.safetensors
DD-made-of-clay-XL-v2.safetensors， 链接：https://huggingface.co/DoctorDiffusion/doctor-diffusion-s-claymation-style-lora/tree/main
LoRAs模型下载完后放在`ComfyUI/models/loras/`目录下

controlnet模型：
control-lora-depth-rank256.safetensors, 链接：https://huggingface.co/stabilityai/control-lora/blob/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors

controlnet_aux模型
depth_anything_vitl14.pth, 链接：https://huggingface.co/spaces/LiheYoung/Depth-Anything/blob/main/checkpoints/depth_anything_vitl14.pth
controlnet_aux模型下载完后放在`ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/LiheYoung/Depth-Anything/checkpoints/`目录下

clip_vision和ipadapter模型的下载说明可参考网页：https://github.com/cubiq/ComfyUI_IPAdapter_plus/tree/main
clip_vision模型：CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors，链接：https://github.com/cubiq/ComfyUI_IPAdapter_plus/tree/main
下载之后，重命名为CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors，然后将其放在`ComfyUI/models/clip_vision/`目录下

ipadapter模型：ip-adapter-plus_sdxl_vit-h.safetensors，链接：https://github.com/cubiq/ComfyUI_IPAdapter_plus/tree/main
下载之后，将其放在`ComfyUI/models/ipadapter/`目录下,由于原来的ComfyUI的代码中没有该目录，需要自己手动创建该目录

## 安装Ollama
```
$ curl -fsSL https://ollama.com/install.sh | sh
```
即可安装Ollama,然后需要下载两个模型llava:7b-v1.6-mistral-fp16 和 llama3:8b-instruct-fp16. 直接运行下面的两个命令即可下载
```
$ ollama run llava:7b-v1.6-mistral-fp16
$ ollama run llama3:8b-instruct-fp16
```
下载完，关掉终端就可以了。


## 生成粘土风格图片
上述所有内容准备完成之后，就可以在终端运行comfyUI进行粘土图片生成了。
```
 (comfyui)$ python main.py 
```
运行comfyUI,然后自己找一张照片，上传到`Load Image`模块，接着点击右边的`Queue Prompt`即可。如果您的显存很大，一般不会报错，如果显存
比较小，中间可能会报`torch.cuda.OutOfMemoryError: Allocation on device 0 would exceed allowed memory`的错误，一般等cuda里面的内存
释放之后再点击`Queue Prompt`就可以运行了。注意报错之后再运行是从刚才报错的地方开始的，所以有点类似于断点的形式。如果GPU内存很小，可以考虑
安装cpu版本的运行。




